\begin{table*}[t]
\centering
\small
\begin{tabular}{lccc ccc}
\toprule
& \multicolumn{3}{c}{\textbf{ScienceWorld (Test)}} & \multicolumn{3}{c}{\textbf{HLE (Test)}} \\
\cmidrule(lr){2-4}\cmidrule(lr){5-7}
\textbf{Method} & Avg Score$\uparrow$ & Total Cost (\$)$\downarrow$ & Avg Turns & Acc. (\%)$\uparrow$ & Total Cost (\$)$\downarrow$ & Avg Turns \\
\midrule
\multicolumn{7}{c}{\textit{Single-Model Baselines}} \\
\midrule
GPT-5 & \textbf{48.4} & \$13.91 & 29.2 & \textbf{25.1} & \$61.77 & 7.0 \\
DeepSeek-V3.2 & 13.1 & \$2.86 & 45.1 & 15.6 & \$22.40 & 26.0 \\
MiniMax-M2 & -0.5 & \$3.22 & 33.0 & 7.8 & \$18.06 & 27.0 \\
Kimi-K2 & 5.2 & \$2.54 & 31.8 & 11.4 & \$12.03 & 16.2 \\
Gemini-Flash & 4.2 & \$0.32 & 30.4 & 5.6 & \$2.97 & 6.8 \\
GPT-OSS-120B & 26.6 & \$0.49 & 32.8 & 9.7 & \$0.71 & 11.4 \\
\midrule
\multicolumn{7}{c}{\textit{Single-Turn Routers (episode-level, fixed model)}} \\
\midrule
RouterDC & -- & -- & -- & -- & -- & -- \\
EmbedLLM & -- & -- & -- & -- & -- & -- \\
Avengers & -- & -- & -- & -- & -- & -- \\
\midrule
\multicolumn{7}{c}{\textit{Multi-Turn Routers}} \\
\midrule
Roulette & 37.7 & \$3.94 & 28.5 & 24.2 & \$28.00 & 10.2 \\
LLM Router & 19.8 & \$12.19 & 36.6 & 24.0 & \$8.52 & 5.8 \\
Router-R1 & -- & -- & -- & -- & -- & -- \\
OpenRouter & -26.4 & \$3.03 & 38.2 & 18.3 & \$40.11 & 5.6 \\
\midrule
\rowcolor{green!10}
\method ($\lambda$=0) & -- & -- & -- & -- & -- & -- \\
\rowcolor{green!10}
\methodplus ($\lambda$=0) & -- & -- & -- & -- & -- & -- \\
\bottomrule
\end{tabular}
\caption{Main results on ScienceWorld and HLE test sets. Avg Score/Avg Turns are per-episode averages (ScienceWorld score in 0--100; HLE accuracy in \%), while Total Cost is summed over evaluated episodes. ``--'' indicates results omitted or not available.}
\label{tab:main_results}
\end{table*}
