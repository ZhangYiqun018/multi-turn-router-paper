% Related Work

\paragraph{LLM Routing and Model Selection.}
The proliferation of LLMs with diverse cost-capability profiles has motivated research on intelligent model selection. \citet{ong2024routellm} train binary classifiers to route between strong and weak models for single-turn queries, while \citet{lu2023routing} frame routing as a multi-armed bandit problem. FrugalGPT \citep{chen2023frugalgpt} cascades models from cheap to expensive until confidence thresholds are met. EmbedLLM \citep{wang2024embedllm} learns embeddings to predict model performance on specific queries. Avengers \citep{zhang2025avengers} combines multiple LLMs through learned gating mechanisms. RouterDC \citep{chen2024routerdc} uses dual contrastive learning for effective router training.

These approaches focus on \emph{single-turn} routing: given a query, select one model to answer it. Our work extends routing to the \emph{multi-turn} setting, where the router must reason about sequential dependencies---early model choices affect future states, requiring credit assignment across episode steps.

\paragraph{LLM Agents and Tool Use.}
LLM agents augmented with tools can perform complex multi-step tasks \citep{schick2023toolformer,qin2023toolllm}. ReAct \citep{yao2023react} interleaves reasoning and action in a single prompt. Toolformer \citep{schick2023toolformer} fine-tunes models to use tools autonomously. Recent work explores agent architectures for software engineering \citep{jimenez2024swebench,yang2024sweagent}, web browsing \citep{zhou2024webarena}, and scientific reasoning \citep{wang2022scienceworld}.

Most agent frameworks assume a fixed underlying model. Our work introduces a routing layer that can dynamically switch between models, treating the model choice as an additional decision at each step. This is orthogonal to agent architecture and can be applied to any multi-turn agent system.
