\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
% Change to "preprint" to generate a non-anonymous version with page numbers.
\usepackage[review]{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

% Including images in your LaTeX document requires adding
% additional package(s)
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usetikzlibrary{shapes,arrows,positioning,fit,backgrounds}

% Define colors for figures
\definecolor{gpt5color}{RGB}{74,144,226}
\definecolor{deepseekcolor}{RGB}{80,200,120}
\definecolor{minimaxcolor}{RGB}{255,165,0}
\definecolor{kimicolor}{RGB}{186,85,211}
\definecolor{geminicolor}{RGB}{255,99,71}
\definecolor{gptosscolor}{RGB}{128,128,128}

\title{Multi-Turn Agentic Model Routing: Learning to Select LLMs for Cost-Effective Agent Evaluation}

\author{Anonymous Authors}

\begin{document}
\maketitle
\begin{abstract}
Multi-turn LLM agents increasingly tackle complex tasks requiring dozens of interaction steps, making the cost-quality trade-off a first-class concern.
We introduce \textsc{LearnedRouter}, a framework for \emph{multi-turn model routing} that dynamically selects which model from a heterogeneous pool to invoke at each step of an agent episode.
Our approach learns a value function over state-model pairs from offline trajectories, enabling deployment-time tuning of the cost-performance trade-off via an adjustable penalty coefficient $\lambda$.
We evaluate on two challenging benchmarks---ScienceWorld (procedural reasoning) and HLE (long-context academic reasoning)---using a pool of six frontier LLMs spanning a 100$\times$ cost range.
\textsc{LearnedRouter} achieves 47.3\% success rate on ScienceWorld (matching the best single model GPT-5) while reducing cost by 59\%, and 22.0\% on HLE with 37\% cost reduction compared to GPT-5.
Analysis reveals that the router learns meaningful patterns: preferring expensive models for initial planning and error recovery, while switching to cheaper alternatives for routine execution.
We release our framework, trajectory dataset, and trained models to facilitate research on cost-aware multi-turn agent evaluation.
\end{abstract}

\section{Introduction}
\input{sections/introduction}

\section{Related Work}
\input{sections/related_work}

\section{Method}
\label{sec:method}
\input{sections/method}

\section{Experiments}
\label{sec:experiments}
\input{sections/experiments}

\section{Conclusion}
\input{sections/conclusion}

\section*{Limitations}
\input{sections/limitations}

\bibliography{custom}

\appendix
\input{sections/appendix}

\end{document}
