% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

%%%%% zyq %%%
@inproceedings{zhang2025beyond,
  title={Beyond gpt-5: Making llms cheaper and better via performance-efficiency optimized routing},
  author={Zhang, Yiqun and Li, Hao and Chen, Jianhao and Zhang, Hangfan and Ye, Peng and Bai, Lei and Hu, Shuyue},
  booktitle={Proceedings of the 2025 7th International Conference on Distributed Artificial Intelligence},
  pages={122--129},
  year={2025}
}
@inproceedings{zhang2025router,
  title={Router-r1: Teaching llms multi-round routing and aggregation via reinforcement learning},
  author={Zhang, Haozhen and Feng, Tao and You, Jiaxuan},
  booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},
  year={2025}
}

@article{team2025tongyi,
  title={Tongyi deepresearch technical report},
  author={Team, Tongyi DeepResearch and Li, Baixuan and Zhang, Bo and Zhang, Dingchu and Huang, Fei and Li, Guangyu and Chen, Guoxin and Yin, Huifeng and Wu, Jialong and Zhou, Jingren and others},
  journal={arXiv preprint arXiv:2510.24701},
  year={2025}
}

@article{liu2023agentbench,
  title={Agentbench: Evaluating llms as agents},
  author={Liu, Xiao and Yu, Hao and Zhang, Hanchen and Xu, Yifan and Lei, Xuanyu and Lai, Hanyu and Gu, Yu and Ding, Hangliang and Men, Kaiwen and Yang, Kejuan and others},
  journal={arXiv preprint arXiv:2308.03688},
  year={2023}
}

@article{hu2025hands,
  title={Hands-on LLM-based Agents: A Tutorial for General Audiences},
  author={Hu, Shuyue and Ren, Siyue and Chen, Yang and Mu, Chunjiang and Liu, Jinyi and Cui, Zhiyao and Zhang, Yiqun and Li, Hao and Zhou, Dongzhan and Xu, Jia and others},
  year={2025}
}

@misc{barres2025tau2benchevaluatingconversationalagents,
      title={$\tau^2$-Bench: Evaluating Conversational Agents in a Dual-Control Environment}, 
      author={Victor Barres and Honghua Dong and Soham Ray and Xujie Si and Karthik Narasimhan},
      year={2025},
      eprint={2506.07982},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2506.07982}, 
}

@misc{gao2025lessempiricalstudyturncontrol,
      title={More with Less: An Empirical Study of Turn-Control Strategies for Efficient Coding Agents}, 
      author={Pengfei Gao and Chao Peng},
      year={2025},
      eprint={2510.16786},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2510.16786}, 
}
%%%%% zyq %%%
@article{wang2022scienceworld,
  title={Scienceworld: Is your agent smarter than a 5th grader?},
  author={Wang, Ruoyao and Jansen, Peter and C{\^o}t{\'e}, Marc-Alexandre and Ammanabrolu, Prithviraj},
  journal={arXiv preprint arXiv:2203.07540},
  year={2022}
}

@article{jimenez2024swebench,
  title={Swe-bench: Can language models resolve real-world github issues?},
  author={Jimenez, Carlos E and Yang, John and Wettig, Alexander and Yao, Shunyu and Pei, Kexin and Press, Ofir and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2310.06770},
  year={2023}
}

@article{yao2022webshop,
  title={WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents},
  author={Yao, Shunyu and Chen, Howard and Yang, John and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={20744--20757},
  year={2022}
}

@article{ong2024routellm,
  title={Routellm: Learning to route llms with preference data},
  author={Ong, Isaac and Almahairi, Amjad and Wu, Vincent and Chiang, Wei-Lin and Wu, Tianhao and Gonzalez, Joseph E and Kadous, M Waleed and Stoica, Ion},
  journal={arXiv preprint arXiv:2406.18665},
  year={2024}
}

@article{lu2023routing,
  title={Routing to the Expert: Efficient Reward-guided Ensemble of Large Language Models},
  author={Lu, Keming and Yuan, Hongyi and Lin, Runji and Lin, Junyang and Yuan, Zheng and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2311.08692},
  year={2023}
}

@article{chen2023frugalgpt,
  title={FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance},
  author={Chen, Lingjiao and Zaharia, Matei and Zou, James},
  journal={arXiv preprint arXiv:2305.05176},
  year={2023}
}

@article{wang2024embedllm,
  title={EmbedLLM: Learning Compact Representations of Large Language Models},
  author={Wang, Qianxin and Chen, Liqi and Chakraborty, Souradip and Dong, Qing and Zhang, Haoran and Liu, Yang and Qi, Zhenghai and Guo, Tianyi and Liu, Meng},
  journal={arXiv preprint arXiv:2401.11623},
  year={2024}
}

@article{zhang2025avengers,
  title={The Avengers: A Simple Recipe for Uniting Smaller Language Models to Challenge Proprietary Giants},
  author={Zhang, Yiqun and Li, Hao and Wang, Chenxu and Chen, Linyao and Zhang, Qiaosheng and Ye, Peng and Feng, Shi and Wang, Daling and Wang, Zhen and Wang, Xinrun and others},
  journal={arXiv preprint arXiv:2505.19797},
  year={2025}
}

@article{chen2024routerdc,
  title={Routerdc: Query-based router by dual contrastive learning for assembling large language models},
  author={Chen, Shuhao and Jiang, Weisen and Lin, Baijiong and Kwok, James and Zhang, Yu},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={66305--66328},
  year={2024}
}

@article{schick2023toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={68539--68551},
  year={2023}
}

@article{qin2023toolllm,
  title={Toolllm: Facilitating large language models to master 16000+ real-world apis},
  author={Qin, Yujia and Liang, Shihao and Ye, Yining and Zhu, Kunlun and Yan, Lan and Lu, Yaxi and Lin, Yankai and Cong, Xin and Tang, Xiangru and Qian, Bill and others},
  journal={arXiv preprint arXiv:2307.16789},
  year={2023}
}

@misc{openrouter,
  title={OpenRouter: Unified API for LLMs and Automatic Routing},
  author={{OpenRouter}},
  howpublished={\url{https://openrouter.ai}},
  year={2025},
  note={Accessed 2026-01-03}
}

@inproceedings{yao2023react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik R and Cao, Yuan},
  booktitle={The eleventh international conference on learning representations},
  year={2022}
}

@article{yang2024sweagent,
  title={Swe-agent: Agent-computer interfaces enable automated software engineering},
  author={Yang, John and Jimenez, Carlos E and Wettig, Alexander and Lieret, Kilian and Yao, Shunyu and Narasimhan, Karthik and Press, Ofir},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={50528--50652},
  year={2024}
}

@article{zhou2024webarena,
  title={Webarena: A realistic web environment for building autonomous agents},
  author={Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Ou, Tianyue and Bisk, Yonatan and Fried, Daniel and others},
  journal={arXiv preprint arXiv:2307.13854},
  year={2023}
}

@inproceedings{leviathan2023speculative,
  title={Fast inference from transformers via speculative decoding},
  author={Leviathan, Yaniv and Kalman, Matan and Matias, Yossi},
  booktitle={International Conference on Machine Learning},
  pages={19274--19286},
  year={2023},
  organization={PMLR}
}

@article{fedus2022switch,
  title={Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
  author={Fedus, William and Zoph, Barret and Shazeer, Noam},
  journal={The Journal of Machine Learning Research},
  volume={23},
  number={1},
  pages={5232--5270},
  year={2022}
}

@article{levine2020offline,
  title={Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@inproceedings{kumar2020cql,
  title={Conservative Q-Learning for Offline Reinforcement Learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1179--1191},
  year={2020}
}

@article{kostrikov2021iql,
  title={Offline Reinforcement Learning with Implicit Q-Learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@inproceedings{li2010linucb,
  title={A Contextual-Bandit Approach to Personalized News Article Recommendation},
  author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  booktitle={Proceedings of the 19th International Conference on World Wide Web},
  pages={661--670},
  year={2010}
}

@inproceedings{agarwal2014contextual,
  title={Taming the Monster: A Fast and Simple Algorithm for Contextual Bandits},
  author={Agarwal, Alekh and Hsu, Daniel and Kale, Satyen and Langford, John and Li, Lihong and Schapire, Robert},
  booktitle={International Conference on Machine Learning},
  pages={1638--1646},
  year={2014}
}

@article{qwen2024,
  title={Qwen2.5 Technical Report},
  author={{Qwen Team}},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}